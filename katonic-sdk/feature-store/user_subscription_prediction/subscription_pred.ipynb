{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Katonic Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Subscription Prediction Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview:\n",
    "Making a prediction on Whether a customer will leave their subscription or not. For that we are using ML model along with the number of features that we ingested into Feature Store.\n",
    "This Demo uses Feature Store with scikit learn to train a model using historical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the FeatureStore functioanlity from Kfs package.\n",
    "\n",
    "from katonic.fs.feature_store import FeatureStore\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After that initiate the Feature Store with the Following Parameters.\n",
    "\n",
    "fs = FeatureStore(    \n",
    "    user_name = \"user\", # e.g. person name \n",
    "    project_name = \"subscriber_churn\", # user name.\n",
    "    description = \"This is a demo for feature store\", # project description.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we’ve configured our infrastructure, let’s register the driver stats features we will use during training and serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've successfully initiated FeatureStore with the Local Provider.\n",
    "# Let's import some more neccessery functions.\n",
    "\n",
    "from katonic.fs.entities import Entity, FeatureView\n",
    "from katonic.fs.core.offline_stores import FileSource\n",
    "from katonic.fs.value_type import ValueType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the Entity key.\n",
    "\n",
    "entity = Entity(name=\"customer_id\", value_type=ValueType.INT64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_source = FileSource(\n",
    "        path = \"datasets/subscription_data.csv\", # Provide a path for your data source file.\n",
    "        file_format = \"csv\",  # format of your data sourse CSV or PARQUET.\n",
    "        event_timestamp_column=\"event_timestamp\", # The column which represents the time of Event occurance.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'BATCH_FILE',\n",
       " 'file_options': {'file_format': 'csv',\n",
       "  'file_url': 'datasets/subscription_data.csv'},\n",
       " 'event_timestamp_column': 'event_timestamp',\n",
       " 'created_timestamp_column': ''}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_source.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature views allow users to register data sources in their organizations into Feature Store for offline feature stores, and then use those offline stores for both training and online inference. \n",
    "\n",
    "The preceding feature view definition tells Feature Store where to find subscription stats features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature View\n",
    "subscription_stats  = FeatureView(\n",
    "    name=\"subscription_stats_fv\", # Feature view name\n",
    "    entities=[\"customer_id\"], # Entity Key\n",
    "    ttl=\"2d\", # hours/months/day # ttl is nothing but the Time period for the feature view Existance.\n",
    "    features=[\"year\", \"no_of_days_subscribed\", \"minimum_daily_mins\", \"maximum_daily_mins\", \"videos_watched\", \"maximum_days_inactive\"],\n",
    "    batch_source=batch_source,  # data source\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our first feature view, we can apply the changes to create our feature registry and configure our infrastructure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Register and deploy feature definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered entity \u001b[1m\u001b[32mcustomer_id\u001b[0m\n",
      "Registered feature view \u001b[1m\u001b[32msubscription_stats_fv\u001b[0m\n",
      "Deploying infrastructure for \u001b[1m\u001b[32msubscription_stats_fv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Write the data to Offline Store.\n",
    "\n",
    "fs.write_table([entity, subscription_stats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding `write_table` function will:\n",
    "\n",
    "- Store all entity and feature view definitions in a local file called registry.db.\n",
    "- Create an empty `SQLite` table for serving driver statistics features.\n",
    "- Ensure that your data sources on `FileSource` are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build a Training Set using the Feature Store Itself.\n",
    "Now we identify the features we want to query from Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Entity Dataframe. Which includes the entity key and event timestamp column.\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"datasets/subscription_entity_df.csv\")\n",
    "\n",
    "# Making sure that the Timestamp column data type is Accurate.\n",
    "df[\"event_timestamp\"] = pd.to_datetime(df[\"event_timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                      int64\n",
       "event_timestamp    datetime64[ns, UTC]\n",
       "churn                            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the historical features from Offline Store for Training a Model.\n",
    "\n",
    "training_df = fs.get_historical_features(\n",
    "    entity_df=df, # Your Entity Data Frame.\n",
    "    feature_view=[\"subscription_stats_fv\"], # Feature View name.\n",
    "    features=[\"year\", \"no_of_days_subscribed\", \"minimum_daily_mins\", \"maximum_daily_mins\", \"videos_watched\", \"maximum_days_inactive\"],\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>churn</th>\n",
       "      <th>year</th>\n",
       "      <th>no_of_days_subscribed</th>\n",
       "      <th>minimum_daily_mins</th>\n",
       "      <th>maximum_daily_mins</th>\n",
       "      <th>videos_watched</th>\n",
       "      <th>maximum_days_inactive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-12 07:00:00+00:00</td>\n",
       "      <td>258594</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>127</td>\n",
       "      <td>6.8</td>\n",
       "      <td>37.57</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-12 07:00:00+00:00</td>\n",
       "      <td>437014</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>54</td>\n",
       "      <td>10.1</td>\n",
       "      <td>36.40</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-12 07:00:00+00:00</td>\n",
       "      <td>601179</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>159</td>\n",
       "      <td>10.4</td>\n",
       "      <td>32.15</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-17 01:00:00+00:00</td>\n",
       "      <td>100198</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>62</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16.81</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-17 01:00:00+00:00</td>\n",
       "      <td>258935</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>122</td>\n",
       "      <td>13.7</td>\n",
       "      <td>41.45</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            event_timestamp  customer_id  churn  year  no_of_days_subscribed  \\\n",
       "0 2021-04-12 07:00:00+00:00       258594      0  2015                    127   \n",
       "1 2021-04-12 07:00:00+00:00       437014      0  2015                     54   \n",
       "2 2021-04-12 07:00:00+00:00       601179      1  2015                    159   \n",
       "3 2021-10-17 01:00:00+00:00       100198      0  2015                     62   \n",
       "4 2021-10-17 01:00:00+00:00       258935      0  2015                    122   \n",
       "\n",
       "   minimum_daily_mins  maximum_daily_mins  videos_watched  \\\n",
       "0                 6.8               37.57               4   \n",
       "1                10.1               36.40               3   \n",
       "2                10.4               32.15               5   \n",
       "3                12.2               16.81               1   \n",
       "4                13.7               41.45               8   \n",
       "\n",
       "   maximum_days_inactive  \n",
       "0                      2  \n",
       "1                      3  \n",
       "2                      3  \n",
       "3                      4  \n",
       "4                      4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have retrieved the complete training dataset, we can:\n",
    "\n",
    "- Drop timestamp columns and the `customerid` column.\n",
    "- Encode categorical features (if any).\n",
    "- Split the training dataframe into a train, validation, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1158 entries, 0 to 1157\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype              \n",
      "---  ------                 --------------  -----              \n",
      " 0   event_timestamp        1158 non-null   datetime64[ns, UTC]\n",
      " 1   customer_id            1158 non-null   int64              \n",
      " 2   churn                  1158 non-null   int64              \n",
      " 3   year                   1158 non-null   int64              \n",
      " 4   no_of_days_subscribed  1158 non-null   int64              \n",
      " 5   minimum_daily_mins     1158 non-null   float64            \n",
      " 6   maximum_daily_mins     1158 non-null   float64            \n",
      " 7   videos_watched         1158 non-null   int64              \n",
      " 8   maximum_days_inactive  1158 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), int64(6)\n",
      "memory usage: 90.5 KB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have retrieved the complete training dataset, we can:\n",
    "\n",
    "- Drop timestamp columns and the `customer_id` column.\n",
    "- Encode categorical features (if any).\n",
    "- Split the training dataframe into a train, validation, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a model with training data.\n",
    "\n",
    "from joblib import dump\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Removing the unnecessary columns and splitting the data into Dependent and Independent Features.\n",
    "# Train model\n",
    "target = \"churn\"\n",
    "\n",
    "train_X = training_df[training_df.columns.drop(target).drop(\"event_timestamp\").drop(\"customer_id\")]\n",
    "train_Y = training_df.loc[:, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>no_of_days_subscribed</th>\n",
       "      <th>minimum_daily_mins</th>\n",
       "      <th>maximum_daily_mins</th>\n",
       "      <th>videos_watched</th>\n",
       "      <th>maximum_days_inactive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>127</td>\n",
       "      <td>6.8</td>\n",
       "      <td>37.57</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>54</td>\n",
       "      <td>10.1</td>\n",
       "      <td>36.40</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>159</td>\n",
       "      <td>10.4</td>\n",
       "      <td>32.15</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>62</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16.81</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>122</td>\n",
       "      <td>13.7</td>\n",
       "      <td>41.45</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  no_of_days_subscribed  minimum_daily_mins  maximum_daily_mins  \\\n",
       "0  2015                    127                 6.8               37.57   \n",
       "1  2015                     54                10.1               36.40   \n",
       "2  2015                    159                10.4               32.15   \n",
       "3  2015                     62                12.2               16.81   \n",
       "4  2015                    122                13.7               41.45   \n",
       "\n",
       "   videos_watched  maximum_days_inactive  \n",
       "0               4                      2  \n",
       "1               3                      3  \n",
       "2               5                      3  \n",
       "3               1                      4  \n",
       "4               8                      4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subscription_pred.bin']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a model with training data.\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(train_X[sorted(train_X)], train_Y)\n",
    "\n",
    "# Save model\n",
    "dump(tree, \"subscription_pred.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can make online predictions with our subscription_pred model, we must populate our online store with feature values. To load features into the online store, we use `publish_table` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views from \u001b[1m\u001b[32m2021-10-01 00:00:00+00:00\u001b[0m to \u001b[1m\u001b[32m2021-11-01 00:00:00+00:00\u001b[0m into the \u001b[1m\u001b[32mredis\u001b[0m online store.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Populating the latest features into Online store.\n",
    "# Features will get materialized that are in between the time period.\n",
    "from datetime import datetime\n",
    "\n",
    "fs.publish_table(\n",
    "    start_ts = datetime(2021, 10, 1),\n",
    "    end_ts = datetime(2021, 11, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will load features from our `offline store` from `start_date` up to the `end_date`. The `publish_table` function can be repeatedly called as more data becomes available in order to keep the online store fresh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching a feature vector at low latency\n",
    "Now we have everything we need to make a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's make the Predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Online features by using the entity keys.\n",
    "\n",
    "customer_ids = [100198, 100756, 101653]\n",
    "test = fs.get_online_features(\n",
    "    entity_rows=[{\"customer_id\": customer_id} for customer_id in customer_ids], # Entity Keys\n",
    "    feature_view=[\"subscription_stats_fv\"], # Feature View name\n",
    "    features=[\"year\", \"no_of_days_subscribed\", \"minimum_daily_mins\", \"maximum_daily_mins\", \"videos_watched\", \"maximum_days_inactive\"],\n",
    ").to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>no_of_days_subscribed</th>\n",
       "      <th>minimum_daily_mins</th>\n",
       "      <th>maximum_daily_mins</th>\n",
       "      <th>videos_watched</th>\n",
       "      <th>maximum_days_inactive</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>27.54</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  no_of_days_subscribed  minimum_daily_mins  maximum_daily_mins  \\\n",
       "0  2015.0                   62.0                12.2               16.81   \n",
       "1  2015.0                  126.0                11.9                9.89   \n",
       "2  2015.0                  191.0                10.9               27.54   \n",
       "\n",
       "   videos_watched  maximum_days_inactive  customer_id  \n",
       "0             1.0                    4.0       100198  \n",
       "1             1.0                    4.0       100756  \n",
       "2             7.0                    3.0       101653  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the model and making the predictions.\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "model = load(\"subscription_pred.bin\")\n",
    "\n",
    "model.predict(test.drop(\"customer_id\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f9d72a65473bded2be97919dafb62541681d663e24ff59994d15fe626c568e4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
