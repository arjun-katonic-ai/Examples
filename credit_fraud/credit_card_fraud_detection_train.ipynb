{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Credit Card Fraud Detection Predictive Models\n",
    "## Introduction\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation.\n",
    "\n",
    "Due to confidentiality issues, there are not provided the original features and more background information about the data.\n",
    "\n",
    "- Features V1, V2, ... V28 are the principal components obtained with PCA;\n",
    "- The only features which have not been transformed with PCA are Time and Amount. Feature Time contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature Amount is the transaction Amount, this feature can be used for example-dependant cost-senstive learning.\n",
    "- Feature Class is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install mlflow ak-minio pandas matplotlib seaborn plotly sklearn catboost lightgbm xgboost boto3 psycopg2-binary \n",
    "# Docker image: katonic/usecase:1.0 / katonic/notebook-env:base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.system(\"pip install mlflow ak-minio pandas matplotlib seaborn plotly sklearn catboost lightgbm xgboost boto3\")\n",
    "os.system(\"pip install mlflow ak-minio pandas matplotlib seaborn plotly sklearn catboost lightgbm xgboost boto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "block:"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# init_notebook_mode(connected=True)\n",
    "# import gc\n",
    "from datetime import datetime \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark import SparkContext, SparkConf\n",
    "# from pyspark.sql import DataFrame, SparkSession, Window\n",
    "# from pyspark.sql.functions import col, expr, monotonically_increasing_id, row_number,current_timestamp\n",
    "from typing import  List\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "import joblib\n",
    "from minio import Minio\n",
    "from subprocess import run, Popen, PIPE\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from  mlflow.tracking import MlflowClient\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine,text\n",
    "from typing import Optional\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine , text\n",
    "from sklearn.feature_selection import RFECV\n",
    "from typing import Optional\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime \n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from io import StringIO\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from  mlflow.tracking import MlflowClient\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from hana_ml import dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!apt-get install build-dep python-psycopg2\n",
    "#!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure Minio access\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://mlflow-minio-service.mlflow.svc.cluster.local:9000'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'minio'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'BS6PpUKnW^Bkc@$l$QAsY$p#l'\n",
    "os.environ['MLFLOW_BASE_URL'] = 'http://mlflow-service.mlflow.svc.cluster.local:5000'\n",
    "\n",
    "# connect to remote server\n",
    "\n",
    "mlflow.set_tracking_uri(os.environ['MLFLOW_BASE_URL'])\n",
    "\n",
    "# Launch the experiment on mlflow\n",
    "experiment_name = \"credit-card-fraud-detection\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "exp_details = mlflow.get_experiment_by_name(experiment_name)\n",
    "exp_id = exp_details.experiment_id\n",
    "\n",
    "client = mlflow.tracking.MlflowClient(os.environ['MLFLOW_BASE_URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "RFC_METRIC = 'gini'  #metric used for RandomForrestClassifier\n",
    "NUM_ESTIMATORS = 100 #number of estimators used for RandomForrestClassifier\n",
    "NO_JOBS = 4 #number of parallel jobs used for RandomForrestClassifier\n",
    "#TRAIN/VALIDATION/TEST SPLIT\n",
    "#VALIDATION\n",
    "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "#CROSS-VALIDATION\n",
    "NUMBER_KFOLDS = 5 #number of KFolds for cross-validation\n",
    "RANDOM_STATE = 2018\n",
    "MAX_ROUNDS = 1000 #lgb iterations\n",
    "EARLY_STOP = 50 #lgb early stop \n",
    "OPT_ROUNDS = 1000  #To be adjusted based on best validation rounds\n",
    "VERBOSE_EVAL = 50 #Print out metric result\n",
    "IS_LOCAL = False\n",
    "\n",
    "MINIO_HOST=\"minio-service.kubeflow:9000\"\n",
    "MINIO_ACCESS_KEY=\"minio\"\n",
    "MINIO_SECRET_KEY=\"minio123\"\n",
    "MINIO_MODEL_BUCKET=\"seldon\"\n",
    "\n",
    "EVENT_TIMESTAMP_ALIAS = \"event_timestamp\"\n",
    "CREATED_TIMESTAMP_ALIAS = \"created_timestamp\"\n",
    "\n",
    "MODEL_NAME = \"cred_fraud_detection-model\"\n",
    "\n",
    "#file_url = \"https://raw.githubusercontent.com/katonic-dev/usecases/master/datasets/\"\n",
    "file_name = \"dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "POSTGRES_ADDRESS = '52.187.120.22' ## INSERT YOUR DB ADDRESS\n",
    "POSTGRES_PORT = '5432'\n",
    "POSTGRES_USERNAME = 'postgres' ## CHANGE THIS TO YOUR POSTGRES USERNAME\n",
    "POSTGRES_PASSWORD = 'katonic@47' ## CHANGE THIS TO YOUR POSTGRES PASSWORD POSTGRES_DBNAME = 'database' ## CHANGE THIS TO YOUR DATABASE NAME\n",
    "POSTGRES_DBNAME = 'postgres' ## CHANGE THIS TO YOUR DATABASE NAME\n",
    "POSTGRES_ENGINE = 'postgres'\n",
    "PROJECT_NAME = 'katonic'\n",
    "PROJECT_SCHEMA = 'demo_credit_fraud'\n",
    "TABLE_TRAIN = 'credit_card_fraud_train'\n",
    "TABLE_INFERENCE = 'credit_card_fraud_inference'\n",
    "TABLE_MODEL = 'credit_fraud_model_meta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "address='137.117.100.87'\n",
    "port='39017'\n",
    "user='system'\n",
    "password='HXEHana1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def get_minio():\n",
    "    return Minio(MINIO_HOST,\n",
    "                    access_key=MINIO_ACCESS_KEY,\n",
    "                    secret_key=MINIO_SECRET_KEY,\n",
    "                    secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def passwrd_parser(POSTGRES_PASSWORD):\n",
    "    POSTGRES_PASSWORD = POSTGRES_PASSWORD.replace(\"@\",\"%40\")\n",
    "    return POSTGRES_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_to_feature_store(POSTGRES_USERNAME,POSTGRES_PASSWORD,POSTGRES_ADDRESS,\n",
    "                       POSTGRES_PORT,POSTGRES_DBNAME,PROJECT_SCHEMA,dataset,table):\n",
    "    postgres_str = (f\"postgresql+psycopg2://{POSTGRES_USERNAME}:{POSTGRES_PASSWORD}@{POSTGRES_ADDRESS}:{POSTGRES_PORT}/{POSTGRES_DBNAME}\")\n",
    "    engine = create_engine(postgres_str)\n",
    "    \n",
    "    query = text(f\"\"\" \n",
    "                CREATE SCHEMA IF NOT EXISTS {PROJECT_SCHEMA} \"\"\")\n",
    "    engine.execute(query)\n",
    "    \n",
    "    #query = text(f\"\"\" \n",
    "    #               DROP TABLE IF EXISTS  {PROJECT_SCHEMA}.{table} CASCADE;\"\"\")\n",
    "    #engine.execute(query)\n",
    "    dataset.to_sql(table, con=engine, schema=PROJECT_SCHEMA, index=False,if_exists='replace',method='multi')\n",
    "    engine.dispose()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_from_feature_store(POSTGRES_USERNAME,POSTGRES_PASSWORD,POSTGRES_ADDRESS,\n",
    "                       POSTGRES_PORT,POSTGRES_DBNAME,PROJECT_SCHEMA,table):\n",
    "    postgres_str = (f\"postgresql+psycopg2://{POSTGRES_USERNAME}:{POSTGRES_PASSWORD}@{POSTGRES_ADDRESS}:{POSTGRES_PORT}/{POSTGRES_DBNAME}\")\n",
    "    engine = create_engine(postgres_str)\n",
    "    df = pd.read_sql('SELECT * FROM {0}.{1}'.format(PROJECT_SCHEMA, table), engine)\n",
    "    engine.dispose()\n",
    "    return df\n",
    "\n",
    "#engine.dispose()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "block:setup"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlpipeline 2021-07-06 07:22:22.863000+00:00\n",
      "seldon 2021-07-06 07:22:20.971000+00:00\n"
     ]
    }
   ],
   "source": [
    "minioClient = get_minio()\n",
    "buckets = minioClient.list_buckets()\n",
    "for bucket in buckets:\n",
    "    print(bucket.name, bucket.creation_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not minioClient.bucket_exists(MINIO_MODEL_BUCKET):\n",
    "    minioClient.make_bucket(MINIO_MODEL_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "block:load_data",
     "prev:setup"
    ]
   },
   "outputs": [],
   "source": [
    "conn = dataframe.ConnectionContext(address,port,user,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "creditcard = dataframe.DataFrame(conn, 'select * from DEMO_CREDIT_CARD.CREDIT_CARD_TRAIN').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#POSTGRES_PASSWORD = passwrd_parser(POSTGRES_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creditcard = read_from_feature_store(POSTGRES_USERNAME,POSTGRES_PASSWORD,POSTGRES_ADDRESS,POSTGRES_PORT,POSTGRES_DBNAME,\n",
    "#                                     PROJECT_SCHEMA,TABLE_TRAIN)\n",
    "creditcard.pop('timestamp')\n",
    "creditcard.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Card Fraud Detection data -  rows: 8000  columns: 32\n"
     ]
    }
   ],
   "source": [
    "print(\"Credit Card Fraud Detection data -  rows:\",creditcard.shape[0],\" columns:\", creditcard.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7975\n",
       "1      25\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creditcard['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Glimpse the data\n",
    "We start by looking to the data features (first 5 rows).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creditcard.iloc[:10000].to_csv(\"creditcardnew.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  Hour  \n",
       "0  149.62      0   0.0  \n",
       "1    2.69      0   0.0  \n",
       "2  378.66      0   0.0  \n",
       "3  123.50      0   0.0  \n",
       "4   69.99      0   0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creditcard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's look into more details to the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:preprocessing",
     "prev:load_data"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4279.859375</td>\n",
       "      <td>-0.296811</td>\n",
       "      <td>0.293426</td>\n",
       "      <td>0.899338</td>\n",
       "      <td>0.214664</td>\n",
       "      <td>-0.025540</td>\n",
       "      <td>0.155782</td>\n",
       "      <td>-0.027891</td>\n",
       "      <td>-0.070411</td>\n",
       "      <td>0.657716</td>\n",
       "      <td>-0.164745</td>\n",
       "      <td>0.639176</td>\n",
       "      <td>-1.026353</td>\n",
       "      <td>0.693202</td>\n",
       "      <td>0.564729</td>\n",
       "      <td>-0.068434</td>\n",
       "      <td>-0.033213</td>\n",
       "      <td>0.278797</td>\n",
       "      <td>-0.058485</td>\n",
       "      <td>-0.055349</td>\n",
       "      <td>0.042946</td>\n",
       "      <td>-0.053775</td>\n",
       "      <td>-0.165255</td>\n",
       "      <td>-0.035068</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.089043</td>\n",
       "      <td>0.023055</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>65.269011</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.762625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3217.315920</td>\n",
       "      <td>1.498426</td>\n",
       "      <td>1.283308</td>\n",
       "      <td>1.089313</td>\n",
       "      <td>1.444948</td>\n",
       "      <td>1.168362</td>\n",
       "      <td>1.323233</td>\n",
       "      <td>1.062697</td>\n",
       "      <td>1.330436</td>\n",
       "      <td>1.155789</td>\n",
       "      <td>1.082961</td>\n",
       "      <td>1.132368</td>\n",
       "      <td>1.509744</td>\n",
       "      <td>1.237561</td>\n",
       "      <td>1.137268</td>\n",
       "      <td>0.982446</td>\n",
       "      <td>0.841912</td>\n",
       "      <td>0.851273</td>\n",
       "      <td>0.791245</td>\n",
       "      <td>0.810957</td>\n",
       "      <td>0.604935</td>\n",
       "      <td>0.951846</td>\n",
       "      <td>0.654163</td>\n",
       "      <td>0.487899</td>\n",
       "      <td>0.601637</td>\n",
       "      <td>0.427164</td>\n",
       "      <td>0.519302</td>\n",
       "      <td>0.403294</td>\n",
       "      <td>0.275646</td>\n",
       "      <td>194.592277</td>\n",
       "      <td>0.055818</td>\n",
       "      <td>0.870703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.066842</td>\n",
       "      <td>-25.640527</td>\n",
       "      <td>-12.389545</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>-7.574798</td>\n",
       "      <td>-12.968670</td>\n",
       "      <td>-23.632502</td>\n",
       "      <td>-3.878658</td>\n",
       "      <td>-7.454841</td>\n",
       "      <td>-2.595325</td>\n",
       "      <td>-10.912819</td>\n",
       "      <td>-3.389510</td>\n",
       "      <td>-11.736729</td>\n",
       "      <td>-4.152532</td>\n",
       "      <td>-7.552342</td>\n",
       "      <td>-12.598419</td>\n",
       "      <td>-5.131549</td>\n",
       "      <td>-4.932733</td>\n",
       "      <td>-13.276034</td>\n",
       "      <td>-11.468435</td>\n",
       "      <td>-8.527145</td>\n",
       "      <td>-15.144340</td>\n",
       "      <td>-2.512377</td>\n",
       "      <td>-2.577363</td>\n",
       "      <td>-1.338556</td>\n",
       "      <td>-7.976100</td>\n",
       "      <td>-3.054085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1543.500000</td>\n",
       "      <td>-1.045736</td>\n",
       "      <td>-0.235993</td>\n",
       "      <td>0.373147</td>\n",
       "      <td>-0.685654</td>\n",
       "      <td>-0.631885</td>\n",
       "      <td>-0.654169</td>\n",
       "      <td>-0.519372</td>\n",
       "      <td>-0.199267</td>\n",
       "      <td>-0.082667</td>\n",
       "      <td>-0.672732</td>\n",
       "      <td>-0.161961</td>\n",
       "      <td>-2.275696</td>\n",
       "      <td>-0.209944</td>\n",
       "      <td>-0.047510</td>\n",
       "      <td>-0.653889</td>\n",
       "      <td>-0.545975</td>\n",
       "      <td>-0.258486</td>\n",
       "      <td>-0.504811</td>\n",
       "      <td>-0.546957</td>\n",
       "      <td>-0.147240</td>\n",
       "      <td>-0.271462</td>\n",
       "      <td>-0.580474</td>\n",
       "      <td>-0.182788</td>\n",
       "      <td>-0.340506</td>\n",
       "      <td>-0.160363</td>\n",
       "      <td>-0.361729</td>\n",
       "      <td>-0.064121</td>\n",
       "      <td>-0.018995</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3639.500000</td>\n",
       "      <td>-0.415531</td>\n",
       "      <td>0.332122</td>\n",
       "      <td>0.947504</td>\n",
       "      <td>0.220104</td>\n",
       "      <td>-0.107874</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>0.616458</td>\n",
       "      <td>-0.260083</td>\n",
       "      <td>0.626849</td>\n",
       "      <td>-1.061161</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>0.569912</td>\n",
       "      <td>0.055018</td>\n",
       "      <td>0.027022</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>-0.025932</td>\n",
       "      <td>-0.050557</td>\n",
       "      <td>-0.007679</td>\n",
       "      <td>-0.129269</td>\n",
       "      <td>-0.163764</td>\n",
       "      <td>-0.046340</td>\n",
       "      <td>0.088791</td>\n",
       "      <td>0.116439</td>\n",
       "      <td>-0.011900</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6723.750000</td>\n",
       "      <td>1.124255</td>\n",
       "      <td>0.947613</td>\n",
       "      <td>1.597241</td>\n",
       "      <td>1.127600</td>\n",
       "      <td>0.404580</td>\n",
       "      <td>0.548985</td>\n",
       "      <td>0.526695</td>\n",
       "      <td>0.305712</td>\n",
       "      <td>1.300277</td>\n",
       "      <td>0.242759</td>\n",
       "      <td>1.423623</td>\n",
       "      <td>0.301357</td>\n",
       "      <td>1.641521</td>\n",
       "      <td>1.404095</td>\n",
       "      <td>0.594866</td>\n",
       "      <td>0.523045</td>\n",
       "      <td>0.750677</td>\n",
       "      <td>0.418391</td>\n",
       "      <td>0.467915</td>\n",
       "      <td>0.172784</td>\n",
       "      <td>0.044328</td>\n",
       "      <td>0.250886</td>\n",
       "      <td>0.086008</td>\n",
       "      <td>0.421131</td>\n",
       "      <td>0.361012</td>\n",
       "      <td>0.333674</td>\n",
       "      <td>0.143984</td>\n",
       "      <td>0.080517</td>\n",
       "      <td>54.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10990.000000</td>\n",
       "      <td>1.685314</td>\n",
       "      <td>8.261750</td>\n",
       "      <td>4.101716</td>\n",
       "      <td>7.380245</td>\n",
       "      <td>11.974269</td>\n",
       "      <td>21.393069</td>\n",
       "      <td>34.303177</td>\n",
       "      <td>3.877662</td>\n",
       "      <td>10.392889</td>\n",
       "      <td>12.259949</td>\n",
       "      <td>7.620089</td>\n",
       "      <td>3.774837</td>\n",
       "      <td>4.465413</td>\n",
       "      <td>5.748734</td>\n",
       "      <td>3.635042</td>\n",
       "      <td>4.087802</td>\n",
       "      <td>6.739384</td>\n",
       "      <td>3.042493</td>\n",
       "      <td>3.097749</td>\n",
       "      <td>8.012574</td>\n",
       "      <td>22.588989</td>\n",
       "      <td>4.534454</td>\n",
       "      <td>13.876221</td>\n",
       "      <td>3.200201</td>\n",
       "      <td>5.525093</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>4.173387</td>\n",
       "      <td>4.860769</td>\n",
       "      <td>7712.430000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time           V1           V2           V3           V4  \\\n",
       "count   8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean    4279.859375    -0.296811     0.293426     0.899338     0.214664   \n",
       "std     3217.315920     1.498426     1.283308     1.089313     1.444948   \n",
       "min        0.000000   -23.066842   -25.640527   -12.389545    -4.657545   \n",
       "25%     1543.500000    -1.045736    -0.235993     0.373147    -0.685654   \n",
       "50%     3639.500000    -0.415531     0.332122     0.947504     0.220104   \n",
       "75%     6723.750000     1.124255     0.947613     1.597241     1.127600   \n",
       "max    10990.000000     1.685314     8.261750     4.101716     7.380245   \n",
       "\n",
       "                V5           V6           V7           V8           V9  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean     -0.025540     0.155782    -0.027891    -0.070411     0.657716   \n",
       "std       1.168362     1.323233     1.062697     1.330436     1.155789   \n",
       "min     -32.092129    -7.574798   -12.968670   -23.632502    -3.878658   \n",
       "25%      -0.631885    -0.654169    -0.519372    -0.199267    -0.082667   \n",
       "50%      -0.107874    -0.150798     0.003556     0.015608     0.616458   \n",
       "75%       0.404580     0.548985     0.526695     0.305712     1.300277   \n",
       "max      11.974269    21.393069    34.303177     3.877662    10.392889   \n",
       "\n",
       "               V10          V11          V12          V13          V14  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean     -0.164745     0.639176    -1.026353     0.693202     0.564729   \n",
       "std       1.082961     1.132368     1.509744     1.237561     1.137268   \n",
       "min      -7.454841    -2.595325   -10.912819    -3.389510   -11.736729   \n",
       "25%      -0.672732    -0.161961    -2.275696    -0.209944    -0.047510   \n",
       "50%      -0.260083     0.626849    -1.061161     0.714290     0.569912   \n",
       "75%       0.242759     1.423623     0.301357     1.641521     1.404095   \n",
       "max      12.259949     7.620089     3.774837     4.465413     5.748734   \n",
       "\n",
       "               V15          V16          V17          V18          V19  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean     -0.068434    -0.033213     0.278797    -0.058485    -0.055349   \n",
       "std       0.982446     0.841912     0.851273     0.791245     0.810957   \n",
       "min      -4.152532    -7.552342   -12.598419    -5.131549    -4.932733   \n",
       "25%      -0.653889    -0.545975    -0.258486    -0.504811    -0.546957   \n",
       "50%       0.055018     0.027022     0.237113    -0.025932    -0.050557   \n",
       "75%       0.594866     0.523045     0.750677     0.418391     0.467915   \n",
       "max       3.635042     4.087802     6.739384     3.042493     3.097749   \n",
       "\n",
       "               V20          V21          V22          V23          V24  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      0.042946    -0.053775    -0.165255    -0.035068     0.025745   \n",
       "std       0.604935     0.951846     0.654163     0.487899     0.601637   \n",
       "min     -13.276034   -11.468435    -8.527145   -15.144340    -2.512377   \n",
       "25%      -0.147240    -0.271462    -0.580474    -0.182788    -0.340506   \n",
       "50%      -0.007679    -0.129269    -0.163764    -0.046340     0.088791   \n",
       "75%       0.172784     0.044328     0.250886     0.086008     0.421131   \n",
       "max       8.012574    22.588989     4.534454    13.876221     3.200201   \n",
       "\n",
       "               V25          V26          V27          V28       Amount  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      0.089043     0.023055     0.015576     0.001087    65.269011   \n",
       "std       0.427164     0.519302     0.403294     0.275646   194.592277   \n",
       "min      -2.577363    -1.338556    -7.976100    -3.054085     0.000000   \n",
       "25%      -0.160363    -0.361729    -0.064121    -0.018995     4.675000   \n",
       "50%       0.116439    -0.011900     0.006538     0.018361    15.950000   \n",
       "75%       0.361012     0.333674     0.143984     0.080517    54.650000   \n",
       "max       5.525093     3.517346     4.173387     4.860769  7712.430000   \n",
       "\n",
       "             Class         Hour  \n",
       "count  8000.000000  8000.000000  \n",
       "mean      0.003125     0.762625  \n",
       "std       0.055818     0.870703  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     1.000000  \n",
       "75%       0.000000     1.000000  \n",
       "max       1.000000     3.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creditcard.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Looking to the Time feature, we can confirm that the data contains 284,807 transactions, during 2 consecutive days (or 172792 seconds).\n",
    "\n",
    "### Check missing data\n",
    "Let's check if there is any missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:missing_value",
     "prev:preprocessing"
    ]
   },
   "outputs": [],
   "source": [
    "total = creditcard.isnull().sum().sort_values(ascending = False)\n",
    "percent = (creditcard.isnull().sum()/creditcard.isnull().count()*100).sort_values(ascending = False)\n",
    "pd.concat([total, percent], axis=1, keys=['Total', 'Percent']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "There is no missing data in the entire dataset.\n",
    "### Data unbalance\n",
    "Let's check data unbalance with respect with target value, i.e. Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#temp = creditcard[\"Class\"].value_counts()\n",
    "#df = pd.DataFrame({'Class': temp.index,'values': temp.values})\n",
    "#\n",
    "#trace = go.Bar(\n",
    "#    x = df['Class'],y = df['values'],\n",
    "#    name=\"Credit Card Fraud Class - data unbalance (Not fraud = 0, Fraud = 1)\",\n",
    "#    marker=dict(color=\"Red\"),\n",
    "#    text=df['values']\n",
    "#)\n",
    "#data = [trace]\n",
    "#layout = dict(title = 'Credit Card Fraud Class - data unbalance (Not fraud = 0, Fraud = 1)',\n",
    "#          xaxis = dict(title = 'Class', showticklabels=True), \n",
    "#          yaxis = dict(title = 'Number of transactions'),\n",
    "#          hovermode = 'closest',width=600\n",
    "#         )\n",
    "#fig = dict(data=data, layout=layout)\n",
    "#iplot(fig, filename='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Only 492 (or 0.172%) of transaction are fraudulent. That means the data is highly unbalanced with respect with target variable Class.\n",
    "\n",
    "## Data exploration\n",
    "#### Transactions in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:data_exploration",
     "prev:missing_value"
    ]
   },
   "outputs": [],
   "source": [
    "#class_0 = creditcard.loc[creditcard['Class'] == 0][\"Time\"]\n",
    "#class_1 = creditcard.loc[creditcard['Class'] == 1][\"Time\"]\n",
    "#\n",
    "#hist_data = [class_0, class_1]\n",
    "#group_labels = ['Not Fraud', 'Fraud']\n",
    "#\n",
    "#fig = ff.create_distplot(hist_data, group_labels, show_hist=False, show_rug=False)\n",
    "#fig['layout'].update(title='Credit Card Transactions Time Density Plot', xaxis=dict(title='Time [s]'))\n",
    "#iplot(fig, filename='dist_only')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Fraudulent transactions have a distribution more even than valid transactions - are equaly distributed in time, including the low real transaction times, during night in Europe timezone.\n",
    "\n",
    "Let's look into more details to the time distribution of both classes transaction, as well as to aggregated values of transaction count and amount, per hour. We assume (based on observation of the time distribution of transactions) that the time unit is second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "creditcard['Time'] = creditcard['Time'].astype('float')\n",
    "creditcard['Hour'] = creditcard['Time'].apply(lambda x: np.floor(x / 3600))\n",
    "\n",
    "tmp = creditcard.groupby(['Hour', 'Class'])['Amount'].aggregate(['min', 'max', 'count', 'sum', 'mean', 'median', 'var']).reset_index()\n",
    "df = pd.DataFrame(tmp)\n",
    "df.columns = ['Hour', 'Class', 'Min', 'Max', 'Transactions', 'Sum', 'Mean', 'Median', 'Var']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18,6))\n",
    "s = sns.lineplot(ax = ax1, x=\"Hour\", y=\"Sum\", data=df.loc[df.Class==0])\n",
    "s = sns.lineplot(ax = ax2, x=\"Hour\", y=\"Sum\", data=df.loc[df.Class==1], color=\"red\")\n",
    "plt.suptitle(\"Total Amount\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18,6))\n",
    "s = sns.lineplot(ax = ax1, x=\"Hour\", y=\"Transactions\", data=df.loc[df.Class==0])\n",
    "s = sns.lineplot(ax = ax2, x=\"Hour\", y=\"Transactions\", data=df.loc[df.Class==1], color=\"red\")\n",
    "plt.suptitle(\"Total Number of Transactions\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18,6))\n",
    "s = sns.lineplot(ax = ax1, x=\"Hour\", y=\"Mean\", data=df.loc[df.Class==0])\n",
    "s = sns.lineplot(ax = ax2, x=\"Hour\", y=\"Mean\", data=df.loc[df.Class==1], color=\"red\")\n",
    "plt.suptitle(\"Average Amount of Transactions\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18,6))\n",
    "s = sns.lineplot(ax = ax1, x=\"Hour\", y=\"Max\", data=df.loc[df.Class==0])\n",
    "s = sns.lineplot(ax = ax2, x=\"Hour\", y=\"Max\", data=df.loc[df.Class==1], color=\"red\")\n",
    "plt.suptitle(\"Maximum Amount of Transactions\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18,6))\n",
    "s = sns.lineplot(ax = ax1, x=\"Hour\", y=\"Median\", data=df.loc[df.Class==0])\n",
    "s = sns.lineplot(ax = ax2, x=\"Hour\", y=\"Median\", data=df.loc[df.Class==1], color=\"red\")\n",
    "plt.suptitle(\"Median Amount of Transactions\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18,6))\n",
    "s = sns.lineplot(ax = ax1, x=\"Hour\", y=\"Min\", data=df.loc[df.Class==0])\n",
    "s = sns.lineplot(ax = ax2, x=\"Hour\", y=\"Min\", data=df.loc[df.Class==1], color=\"red\")\n",
    "plt.suptitle(\"Minimum Amount of Transactions\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Transactions amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n",
    "s = sns.boxplot(ax = ax1, x=\"Class\", y=\"Amount\", hue=\"Class\",data=creditcard, palette=\"PRGn\",showfliers=True)\n",
    "s = sns.boxplot(ax = ax2, x=\"Class\", y=\"Amount\", hue=\"Class\",data=creditcard, palette=\"PRGn\",showfliers=False)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = creditcard[['Amount','Class']].copy()\n",
    "class_0 = tmp.loc[tmp['Class'] == 0]['Amount']\n",
    "class_1 = tmp.loc[tmp['Class'] == 1]['Amount']\n",
    "class_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The real transaction have a larger mean value, larger Q1, smaller Q3 and Q4 and larger outliers; fraudulent transactions have a smaller Q1 and mean, larger Q4 and smaller outliers.\n",
    "\n",
    "Let's plot the fraudulent transactions (amount) against time. The time is shown is seconds from the start of the time period (totaly 48h, over 2 days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fraud = creditcard.loc[creditcard['Class'] == 1]\n",
    "\n",
    "# trace = go.Scatter(\n",
    "#     x = fraud['Time'],y = fraud['Amount'],\n",
    "#     name=\"Amount\",\n",
    "#      marker=dict(\n",
    "#                 color='rgb(238,23,11)',\n",
    "#                 line=dict(\n",
    "#                     color='red',\n",
    "#                     width=1),\n",
    "#                 opacity=0.5,\n",
    "#             ),\n",
    "#     text= fraud['Amount'],\n",
    "#     mode = \"markers\"\n",
    "# )\n",
    "# data = [trace]\n",
    "# layout = dict(title = 'Amount of fraudulent transactions',\n",
    "#           xaxis = dict(title = 'Time [s]', showticklabels=True), \n",
    "#           yaxis = dict(title = 'Amount'),\n",
    "#           hovermode='closest'\n",
    "#          )\n",
    "# fig = dict(data=data, layout=layout)\n",
    "# iplot(fig, filename='fraud-amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Features correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "As expected, there is no notable correlation between features V1-V28. There are certain correlations between some of these features and Time (inverse correlation with V3) and Amount (direct correlation with V7 and V20, inverse correlation with V1 and V5).\n",
    "\n",
    "Let's plot the correlated and inverse correlated values on the same graph.\n",
    "\n",
    "Let's start with the direct correlated values: {V20;Amount} and {V7;Amount}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,14))\n",
    "plt.title('Credit Card Transactions features correlation plot (Pearson)')\n",
    "corr = creditcard.corr()\n",
    "sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"Reds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = sns.lmplot(x='V20', y='Amount',data=creditcard, hue='Class', fit_reg=True,scatter_kws={'s':2})\n",
    "s = sns.lmplot(x='V7', y='Amount',data=creditcard, hue='Class', fit_reg=True,scatter_kws={'s':2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can confirm that the two couples of features are correlated (the regression lines for Class = 0 have a positive slope, whilst the regression line for Class = 1 have a smaller positive slope).\n",
    "\n",
    "Let's plot now the inverse correlated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = sns.lmplot(x='V2', y='Amount',data=creditcard, hue='Class', fit_reg=True,scatter_kws={'s':2})\n",
    "s = sns.lmplot(x='V5', y='Amount',data=creditcard, hue='Class', fit_reg=True,scatter_kws={'s':2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can confirm that the two couples of features are inverse correlated (the regression lines for Class = 0 have a negative slope while the regression lines for Class = 1 have a very small negative slope).\n",
    "\n",
    "#### Features density plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "creditcard['V1'] = creditcard['V1'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "var = creditcard.columns.values\n",
    "\n",
    "i = 0\n",
    "t0 = creditcard.loc[creditcard['Class'] == 0]\n",
    "t1 = creditcard.loc[creditcard['Class'] == 1]\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(8,4,figsize=(16,28))\n",
    "\n",
    "for feature in var:\n",
    "    i += 1\n",
    "    plt.subplot(8,4,i)\n",
    "    sns.kdeplot(t0[feature], bw=0.5,label=\"Class = 0\")\n",
    "    sns.kdeplot(t1[feature], bw=0.5,label=\"Class = 1\")\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For some of the features we can observe a good selectivity in terms of distribution for the two values of Class: V4, V11 have clearly separated distributions for Class values 0 and 1, V12, V14, V18 are partially separated, V1, V2, V3, V10 have a quite distinct profile, whilst V25, V26, V28 have similar profiles for the two values of Class.\n",
    "\n",
    "In general, with just few exceptions (Time and Amount), the features distribution for legitimate transactions (values of Class = 0) is centered around 0, sometime with a long queue at one of the extremities. In the same time, the fraudulent transactions (values of Class = 1) have a skewed (asymmetric) distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predictive models\n",
    "Define predictors and target values\n",
    "Let's define the predictor features and the target features. Categorical features, if any, are also defined. In our case, there are no categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:train_test_split",
     "prev:preprocessing",
     "prev:data_exploration",
     "prev:missing_value"
    ]
   },
   "outputs": [],
   "source": [
    "target = 'Class'\n",
    "predictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n",
    "       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n",
    "       'Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split data in train, test and validation set\n",
    "Let's define train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(creditcard, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True )\n",
    "#train_df, valid_df = train_test_split(creditcard, test_size=VALID_SIZE, random_state=RANDOM_STATE, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_df[predictors], test_df[predictors]\n",
    "y_train, y_test = train_df[target], test_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:logistic_regression",
     "prev:train_test_split"
    ]
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"logistic_regression\"):\n",
    "    clf = LogisticRegression(random_state=0, max_iter=50, l1_ratio=0.8, penalty='elasticnet', solver='saga')\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    \n",
    "    y_pred_tr = clf.predict(X_train)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_tr)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_tr)\n",
    "    \n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"train_auc\", roc_auc_train)\n",
    "    mlflow.log_metric(\"test_auc\", roc_auc_test)\n",
    "    \n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    \n",
    "    mlflow.sklearn.log_model(clf, f\"logistic_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train,y_pred_tr)\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTraining Accuracy Percentage\\033[0m: %.2f' % (train_accuracy*100))\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTesting Accuracy Percentage\\033[0m: %.2f' % (accuracy*100))\n",
    "\n",
    "print('================================================================================================================')\n",
    "print('\\033[1mClassification_report for testing \\033[0m')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\033[1mClassification_report for training \\033[0m')\n",
    "\n",
    "print(classification_report(y_train,y_pred_tr))\n",
    "\n",
    "print('================================================================================================================')\n",
    "#print('\\033[1mConfusion_Matrix\\033[0m')\n",
    "#confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "##group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "#group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "#                confusion_matrix.flatten()]\n",
    "#group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "#                     confusion_matrix.flatten()/np.sum(confusion_matrix)]\n",
    "#\n",
    "#group_description = ['The person paid on time\\n and model also predicted\\n paid on time',\n",
    "#                     'The person paid on time\\n and model predicted paid late',\n",
    "#                    'The person paid late\\n and model predicted paid\\n on time',\n",
    "#                     'The person paid late\\n and model also predicted\\n paid late']\n",
    "#labels = [f\"{v3}\\n{v1}\\n{v2}\" for v1, v2, v3 in\n",
    "#          zip(group_percentages,group_description,group_counts)]\n",
    "#labels = np.asarray(labels).reshape(2,2)\n",
    "#\n",
    "#fig, ax = plt.subplots(figsize=(9,7))\n",
    "#sns.heatmap(confusion_matrix, annot=labels, fmt='', cmap='Blues',\n",
    "#            annot_kws={'fontsize':'large','fontweight':'bold'}\n",
    "#           ,cbar=False,xticklabels=['Predicted on time','Predicted late paid']\n",
    "#            ,yticklabels=['Actual on time','Actual late paid'])\n",
    "#\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:gradient_boost_classifier",
     "prev:train_test_split"
    ]
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"GradientBoostingClassifier\"):\n",
    "    clf = GradientBoostingClassifier(random_state = 42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    \n",
    "    y_pred_tr = clf.predict(X_train)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_tr)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_tr)\n",
    "    \n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"train_auc\", roc_auc_train)\n",
    "    mlflow.log_metric(\"test_auc\", roc_auc_test)\n",
    "    \n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    \n",
    "    mlflow.sklearn.log_model(clf, f\"GradientBoostingClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train,y_pred_tr)\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTraining Accuracy Percentage\\033[0m: %.2f' % (train_accuracy*100))\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTesting Accuracy Percentage\\033[0m: %.2f' % (accuracy*100))\n",
    "\n",
    "print('================================================================================================================')\n",
    "print('\\033[1mClassification_report for testing \\033[0m')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\033[1mClassification_report for training \\033[0m')\n",
    "\n",
    "print(classification_report(y_train,y_pred_tr))\n",
    "\n",
    "print('================================================================================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:random_forest_classifier",
     "prev:train_test_split"
    ]
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"RandomForestClassifier\"):\n",
    "    clf = RandomForestClassifier(random_state = 42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    \n",
    "    y_pred_tr = clf.predict(X_train)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_tr)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_tr)\n",
    "    \n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"train_auc\", roc_auc_train)\n",
    "    mlflow.log_metric(\"test_auc\", roc_auc_test)\n",
    "    \n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    \n",
    "    mlflow.sklearn.log_model(clf, f\"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train,y_pred_tr)\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTraining Accuracy Percentage\\033[0m: %.2f' % (train_accuracy*100))\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTesting Accuracy Percentage\\033[0m: %.2f' % (accuracy*100))\n",
    "\n",
    "print('================================================================================================================')\n",
    "print('\\033[1mClassification_report for testing \\033[0m')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\033[1mClassification_report for training \\033[0m')\n",
    "\n",
    "print(classification_report(y_train,y_pred_tr))\n",
    "\n",
    "print('================================================================================================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:ada_boost_classifier",
     "prev:train_test_split"
    ]
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"AdaBoostClassifier\"):\n",
    "    clf = AdaBoostClassifier(random_state = 42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    \n",
    "    y_pred_tr = clf.predict(X_train)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_tr)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_tr)\n",
    "    \n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"train_auc\", roc_auc_train)\n",
    "    mlflow.log_metric(\"test_auc\", roc_auc_test)\n",
    "    \n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    \n",
    "    mlflow.sklearn.log_model(clf, f\"AdaBoostClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train,y_pred_tr)\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTraining Accuracy Percentage\\033[0m: %.2f' % (train_accuracy*100))\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTesting Accuracy Percentage\\033[0m: %.2f' % (accuracy*100))\n",
    "\n",
    "print('================================================================================================================')\n",
    "print('\\033[1mClassification_report for testing \\033[0m')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\033[1mClassification_report for training \\033[0m')\n",
    "\n",
    "print(classification_report(y_train,y_pred_tr))\n",
    "\n",
    "print('================================================================================================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:cat_boost_classifier",
     "prev:train_test_split"
    ]
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"CatBoostClassifier\"):\n",
    "    clf = CatBoostClassifier(random_seed = 42)\n",
    "    clf.fit(X_train, y_train,verbose=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    y_pred_tr = clf.predict(X_train)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_tr)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_tr)\n",
    "    \n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"train_auc\", roc_auc_train)\n",
    "    mlflow.log_metric(\"test_auc\", roc_auc_test)\n",
    "    \n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    \n",
    "    mlflow.sklearn.log_model(clf, f\"CatBoostClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train,y_pred_tr)\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTraining Accuracy Percentage\\033[0m: %.2f' % (train_accuracy*100))\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTesting Accuracy Percentage\\033[0m: %.2f' % (accuracy*100))\n",
    "\n",
    "print('================================================================================================================')\n",
    "print('\\033[1mClassification_report for testing \\033[0m')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\033[1mClassification_report for training \\033[0m')\n",
    "\n",
    "print(classification_report(y_train,y_pred_tr))\n",
    "\n",
    "print('================================================================================================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select the run of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:runs",
     "prev:random_forest_classifier",
     "prev:ada_boost_classifier",
     "prev:cat_boost_classifier",
     "prev:gradient_boost_classifier",
     "prev:logistic_regression"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "df_runs = mlflow.search_runs(experiment_ids=exp_id)\n",
    "print(\"Number of runs done : \", len(df_runs))\n",
    "print(df_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluating  Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:model_evaluation",
     "prev:runs"
    ]
   },
   "outputs": [],
   "source": [
    "top_runs = df_runs.sort_values(['metrics.test_auc'],ascending=False)\n",
    "top_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Selecting best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:select_best_model",
     "prev:model_evaluation"
    ]
   },
   "outputs": [],
   "source": [
    "artifacts = top_runs.iloc[0][\"artifact_uri\"]\n",
    "run_id = top_runs.iloc[0][\"run_id\"]\n",
    "model_name = top_runs.iloc[0][\"tags.mlflow.runName\"] \n",
    "\n",
    "\n",
    "print('Best model_artifacts :',artifacts)\n",
    "print(\"=\" * 100)\n",
    "print('Best model run_id :',run_id)\n",
    "print(\"=\" * 100)\n",
    "print('Best model :',model_name)\n",
    "print(\"=\" * 100)\n",
    "print(\"Best model experiment id :\",exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Registering best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:register_best_model",
     "prev:select_best_model"
    ]
   },
   "outputs": [],
   "source": [
    "result = mlflow.register_model(\n",
    "    \"runs:/\" + run_id,\n",
    "    MODEL_NAME+'_'+model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Registered model information :')\n",
    "print('=='*50)\n",
    "print(pd.DataFrame(result, columns =['Attribute','Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Experiment information :')\n",
    "print('=='*50)\n",
    "print(pd.DataFrame(exp_details, columns =['Attribute','Value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## storing best model address for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:deploy_model",
     "prev:register_best_model"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "time = pd.to_datetime(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictionary = [{\"model\":model_name,\n",
    "             \"location\":artifacts+'/'+model_name,\n",
    "             \"run_id\":run_id,\n",
    "            'experiment_id':exp_id,\n",
    "              'prod_time':time,\n",
    "              'top_features':predictors,\n",
    "              }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(dictionary)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_PASSWORD = passwrd_parser(POSTGRES_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_to_feature_store(POSTGRES_USERNAME,POSTGRES_PASSWORD,POSTGRES_ADDRESS,\n",
    "                       POSTGRES_PORT,POSTGRES_DBNAME,PROJECT_SCHEMA,dataset,TABLE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "katonic/usecaseb1:4.0",
   "experiment": {
    "id": "new",
    "name": "credit-fraud"
   },
   "experiment_name": "credit-fraud",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "credit-fraud-training",
   "pipeline_name": "credit-fraud-training",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwo",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
