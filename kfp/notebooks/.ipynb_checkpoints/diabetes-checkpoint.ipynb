{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61e3b1d-cc35-4832-9974-06fa08d97f6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This Notebooks focuces on how to use kaml package with kfp sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038356fb-f145-4737-8890-e8677630f227",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp==1.8.22\n",
      "  Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.9/304.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py<2,>=0.9\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyYAML<7,>=5.3\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.9/738.9 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-storage<3,>=1.20.0\n",
      "  Downloading google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kubernetes<26,>=8.0.0\n",
      "  Downloading kubernetes-25.3.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-api-python-client<2,>=1.7.8\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.1\n",
      "  Downloading google_auth-2.23.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.4/181.4 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<1,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jsonschema<5,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from kfp==1.8.22) (4.17.3)\n",
      "Collecting tabulate<1,>=0.8.6\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting click<9,>=7.1.2\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Deprecated<2,>=1.2.7\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting strip-hints<1,>=0.1.8\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Collecting kfp-pipeline-spec<0.2.0,>=0.1.16\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting protobuf<4,>=3.13.0\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uritemplate<4,>=3.0.1\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: urllib3<2 in /opt/conda/lib/python3.9/site-packages (from kfp==1.8.22) (1.26.12)\n",
      "Collecting pydantic<2,>=1.8.2\n",
      "  Downloading pydantic-1.10.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typer<1.0,>=0.3.2\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from fire<1,>=0.3.1->kfp==1.8.22) (1.16.0)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (2.28.1)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httplib2<1dev,>=0.15.0\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.0.3\n",
      "  Downloading google_auth_httplib2-0.1.1-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.6.0-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema<5,>=3.0.1->kfp==1.8.22) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema<5,>=3.0.1->kfp==1.8.22) (0.19.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.22) (2022.9.24)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.22) (2.8.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.9/site-packages (from kubernetes<26,>=8.0.0->kfp==1.8.22) (65.4.0)\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.9/site-packages (from kubernetes<26,>=8.0.0->kfp==1.8.22) (1.4.2)\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from strip-hints<1,>=0.1.8->kfp==1.8.22) (0.37.1)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (3.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: kfp, fire, kfp-server-api, strip-hints\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=426971 sha256=b2796c26b8372e2afc1ec071c872be64bcee7732112e8dfa58539c659d22764e\n",
      "  Stored in directory: /root/.cache/pip/wheels/94/d5/34/5d9359ed9583e1807308241a87f9dd8f9a89e21deef63da655\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116933 sha256=184b329f1c71c302fe7acac87c7b8ac04049384989797a66ee7b803182286ea2\n",
      "  Stored in directory: /root/.cache/pip/wheels/34/a9/61/d515d3cd1e8a349fed305bc67a9c7d68fc38d51053b6decad6\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99701 sha256=6a4e8ecf68f8ef501cd8e8302a8dc3dc43b831248ad26e6e08c6b9dad107da33\n",
      "  Stored in directory: /root/.cache/pip/wheels/1d/5e/cc/d6c7bfba9ec05cf878694715074232539159539737f01bc680\n",
      "  Building wheel for strip-hints (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22284 sha256=883c6184649dc2f2eef8ea97bee623e68eff942015ae97e8184a75e3b9d36d01\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/7d/5a/867fa96b7d29e9dc3f26ddffe45d960690603b434081da419d\n",
      "Successfully built kfp fire kfp-server-api strip-hints\n",
      "Installing collected packages: wrapt, uritemplate, typing-extensions, termcolor, tabulate, strip-hints, PyYAML, pyparsing, pyasn1, protobuf, oauthlib, google-crc32c, docstring-parser, cloudpickle, click, cachetools, absl-py, typer, rsa, requests-toolbelt, requests-oauthlib, pydantic, pyasn1-modules, kfp-server-api, kfp-pipeline-spec, httplib2, googleapis-common-protos, google-resumable-media, fire, Deprecated, google-auth, kubernetes, google-auth-httplib2, google-api-core, google-cloud-core, google-api-python-client, google-cloud-storage, kfp\n",
      "Successfully installed Deprecated-1.2.14 PyYAML-6.0.1 absl-py-1.4.0 cachetools-5.3.1 click-8.1.7 cloudpickle-2.2.1 docstring-parser-0.15 fire-0.5.0 google-api-core-2.11.1 google-api-python-client-1.12.11 google-auth-2.23.0 google-auth-httplib2-0.1.1 google-cloud-core-2.3.3 google-cloud-storage-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.6.0 googleapis-common-protos-1.60.0 httplib2-0.22.0 kfp-1.8.22 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.5 kubernetes-25.3.0 oauthlib-3.2.2 protobuf-3.20.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 pydantic-1.10.12 pyparsing-3.1.1 requests-oauthlib-1.3.1 requests-toolbelt-0.10.1 rsa-4.9 strip-hints-0.1.10 tabulate-0.9.0 termcolor-2.3.0 typer-0.9.0 typing-extensions-4.7.1 uritemplate-3.0.1 wrapt-1.15.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kfp==1.8.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3eb11c1-5986-4646-9bc4-470c900ecce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import components\n",
    "from kfp import dsl\n",
    "from typing import List\n",
    "import kfp\n",
    "from typing import NamedTuple\n",
    "from kfp.components import func_to_container_op, create_component_from_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02545bf-6cc0-4d5e-be71-641b91f88d2e",
   "metadata": {},
   "source": [
    "## Split data\n",
    "\n",
    "- This method loads the data from the `https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv`, splits it into `x_train, x_test, y_train, y_test` and  saves it as `train.csv` and `test.csv`\n",
    "    to `storage_path+'/diabetes.csv'` and returns storage_path\n",
    "    parameters\n",
    "    --------------\n",
    "    data_path: str\n",
    "        path where data need to be saved\n",
    "        \n",
    "    Returns\n",
    "    -------------\n",
    "    none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0687083e-c6ea-40aa-bc4f-2641ec50dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(input_data:str, data_path: str):\n",
    "    import os\n",
    "    os.system(\"pip install pandas scikit-learn\")\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    df = pd.read_csv(input_data)\n",
    "    x = df.drop(columns=['Outcome'], axis=1)\n",
    "    y = df['Outcome']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    x_train['outcome'] = y_train\n",
    "    x_test['outcome'] = y_test\n",
    "\n",
    "    x_train.to_csv(data_path+'/train.csv', index=False)\n",
    "    x_test.to_csv(data_path+'/test.csv', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76272bc8-fe59-4207-90dd-b93d45024a15",
   "metadata": {},
   "source": [
    "## Create classifier\n",
    "\n",
    "- This method installs requirements for kaml package and the package itself, reads the train.csv and test.csv file, then creates a Classifier object by passing `x_train,x_test,y_train,y_test, exp_name` to the class then saves the clf object as a pkl file because objects can't be passes between components\n",
    "    parameters\n",
    "    ------------\n",
    "    exp_name: str\n",
    "        The experiment name that to be created in kaml\n",
    "        \n",
    "    Returns\n",
    "    -------------\n",
    "    none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "292ac19e-63a1-47ed-aa97-07f62fdcb6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(exp_name: str):\n",
    "    import os\n",
    "    # os.system(\"pip install -r /kfs_private/requirements.txt\")\n",
    "    os.system(\"pip install katonic numpy optuna==3.3.0 boto3==1.28.45 protobuf==3.20.1\")\n",
    "    os.system('pip install ipython joblib pandas')\n",
    "    import pandas as pd\n",
    "    # from kaml.classification import Classifier\n",
    "    from katonic.ml.classification import Classifier\n",
    "    from katonic.ml.client import set_exp\n",
    "    import joblib\n",
    "    \n",
    "    train = pd.read_csv('/kfs_private/data_dir/train.csv')\n",
    "    test = pd.read_csv('/kfs_private/data_dir/test.csv')\n",
    "    x_train, y_train = train.drop(columns=['outcome'], axis=1), train['outcome']\n",
    "    x_test, y_test = test.drop(columns=['outcome'], axis=1), test['outcome']\n",
    "    \n",
    "    set_exp(exp_name=exp_name)\n",
    "    clf = Classifier(\n",
    "      x_train,\n",
    "      x_test,\n",
    "      y_train,\n",
    "      y_test,\n",
    "      exp_name)\n",
    "    clf.LogisticRegression()\n",
    "    \n",
    "    joblib.dump(clf, '/kfs_private/katflow_clf.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54ad1c-9892-4da4-ab6d-55d06e675b96",
   "metadata": {},
   "source": [
    "## decision tree\n",
    "- This method installs requirements for kaml package and the package itself, then reads the saved clf object and trains the `DecisionTreeClassifier`\n",
    "\n",
    "    classifier object needs to be read to use this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "49ca74fd-96f8-4131-bdfb-7071a132810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(exp_name: str):\n",
    "    import os\n",
    "    # os.system(\"pip install -r /kfs_private/requirements.txt\")\n",
    "    os.system(\"pip install katonic numpy optuna==3.3.0 boto3==1.28.45 protobuf==3.20.1\")\n",
    "    os.system('pip install ipython joblib pandas')\n",
    "    import pandas as pd\n",
    "    # from kaml.classification import Classifier\n",
    "    from katonic.ml.classification import Classifier\n",
    "    from katonic.ml.client import set_exp\n",
    "    import joblib\n",
    "    \n",
    "    train = pd.read_csv('/kfs_private/data_dir/train.csv')\n",
    "    test = pd.read_csv('/kfs_private/data_dir/test.csv')\n",
    "    x_train, y_train = train.drop(columns=['outcome'], axis=1), train['outcome']\n",
    "    x_test, y_test = test.drop(columns=['outcome'], axis=1), test['outcome']\n",
    "    \n",
    "    set_exp(exp_name=exp_name)\n",
    "    clf = Classifier(\n",
    "      x_train,\n",
    "      x_test,\n",
    "      y_train,\n",
    "      y_test,\n",
    "      exp_name)\n",
    "    clf.DecisionTreeClassifier(max_depth=8, criterion='gini', min_samples_split=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8974b95a-c58d-4c82-be33-274d100a3cb4",
   "metadata": {},
   "source": [
    "## random forest\n",
    "- This method installs requirements for kaml package and the package itself, then clf object is read and `RandomForestClassifier` is tuned using a set of hyperparameters\n",
    "\n",
    "    classifier object needs to be read to use this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0c0955c-7ae6-42e4-893c-fb71639fe66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(exp_name: str):\n",
    "    import os\n",
    "    # os.system(\"pip install -r /kfs_private/requirements.txt\")\n",
    "    os.system(\"pip install katonic numpy optuna==3.3.0 boto3==1.28.45 protobuf==3.20.1\")\n",
    "    os.system('pip install ipython joblib pandas')\n",
    "    import pandas as pd\n",
    "    # from kaml.classification import Classifier\n",
    "    from katonic.ml.classification import Classifier\n",
    "    from katonic.ml.client import set_exp\n",
    "    import joblib\n",
    "    \n",
    "    train = pd.read_csv('/kfs_private/data_dir/train.csv')\n",
    "    test = pd.read_csv('/kfs_private/data_dir/test.csv')\n",
    "    x_train, y_train = train.drop(columns=['outcome'], axis=1), train['outcome']\n",
    "    x_test, y_test = test.drop(columns=['outcome'], axis=1), test['outcome']\n",
    "    \n",
    "    set_exp(exp_name=exp_name)\n",
    "    clf = Classifier(\n",
    "      x_train,\n",
    "      x_test,\n",
    "      y_train,\n",
    "      y_test,\n",
    "      exp_name)\n",
    "    params = {\n",
    "    'n_estimators': {\n",
    "        'low': 80,\n",
    "        'high': 120,\n",
    "        'step': 10,\n",
    "        'type': 'int'\n",
    "        },\n",
    "    'criterion':{\n",
    "        'values': ['gini', 'entropy'],\n",
    "        'type': 'categorical'\n",
    "        },\n",
    "    'min_samples_split': {\n",
    "        'low': 2,\n",
    "        'high': 5,\n",
    "        'type': 'int'\n",
    "        },\n",
    "    'min_samples_leaf':{\n",
    "        'low': 1,\n",
    "        'high': 5,\n",
    "        'type': 'int'\n",
    "        }\n",
    "    }\n",
    "    clf.RandomForestClassifier(is_tune=True,n_trials=5, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0cbcb-4c19-4cd3-a779-b06bbad8e09e",
   "metadata": {},
   "source": [
    "## show runs\n",
    "- This method installs requirements for kaml package and the package itself, then clf object is read and different information about the experiment is printed along with some data about the runs that we performed earlier\n",
    "\n",
    "    classifier object needs to be read to use this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4d19419-7ed7-4c69-bac5-99e3b31078c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_runs(exp_name: str):\n",
    "    import os\n",
    "    # os.system(\"pip install -r /kfs_private/requirements.txt\")\n",
    "    os.system(\"pip install katonic numpy optuna==3.3.0 boto3==1.28.45 protobuf==3.20.1\")\n",
    "    os.system('pip install ipython joblib pandas')\n",
    "    import pandas as pd\n",
    "    # from kaml.classification import Classifier\n",
    "    from katonic.ml.classification import Classifier\n",
    "    from katonic.ml.client import set_exp\n",
    "    import joblib\n",
    "    \n",
    "    train = pd.read_csv('/kfs_private/data_dir/train.csv')\n",
    "    test = pd.read_csv('/kfs_private/data_dir/test.csv')\n",
    "    x_train, y_train = train.drop(columns=['outcome'], axis=1), train['outcome']\n",
    "    x_test, y_test = test.drop(columns=['outcome'], axis=1), test['outcome']\n",
    "    \n",
    "    set_exp(exp_name=exp_name)\n",
    "    clf = Classifier(\n",
    "      x_train,\n",
    "      x_test,\n",
    "      y_train,\n",
    "      y_test,\n",
    "      exp_name)\n",
    "    \n",
    "    clf = joblib.load(open('/kfs_private/katflow_clf.pkl', 'rb'))\n",
    "    \n",
    "    exp_id = clf.id\n",
    "    print(\"experiment name : \",clf.name)\n",
    "    print(\"experiment location : \",clf.location)\n",
    "    print(\"experiment id : \",clf.id)\n",
    "    print(\"experiment status : \",clf.stage)\n",
    "    df_runs = clf.search_runs(exp_id)\n",
    "    print(\"Number of runs done : \", len(df_runs))\n",
    "    print(df_runs[['run_name', 'start_time', 'status']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3b84df0c-c78f-4e11-8b1b-614c4966f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_best_model(exp_name: str):\n",
    "    import os\n",
    "    # os.system(\"pip install -r /kfs_private/requirements.txt\")\n",
    "    os.system(\"pip install katonic numpy optuna==3.3.0 boto3==1.28.45 protobuf==3.20.1\")\n",
    "    os.system('pip install ipython joblib pandas')\n",
    "    import pandas as pd\n",
    "    # from kaml.classification import Classifier\n",
    "    from katonic.ml.classification import Classifier\n",
    "    from katonic.ml.client import set_exp\n",
    "    import joblib\n",
    "    \n",
    "    train = pd.read_csv('/kfs_private/data_dir/train.csv')\n",
    "    test = pd.read_csv('/kfs_private/data_dir/test.csv')\n",
    "    x_train, y_train = train.drop(columns=['outcome'], axis=1), train['outcome']\n",
    "    x_test, y_test = test.drop(columns=['outcome'], axis=1), test['outcome']\n",
    "    \n",
    "    set_exp(exp_name=exp_name)\n",
    "    clf = Classifier(\n",
    "      x_train,\n",
    "      x_test,\n",
    "      y_train,\n",
    "      y_test,\n",
    "      exp_name)\n",
    "    \n",
    "    clf = joblib.load(open('/kfs_private/katflow_clf.pkl', 'rb'))\n",
    "    \n",
    "    exp_id = clf.id\n",
    "    print(\"experiment name : \",clf.name)\n",
    "    print(\"experiment location : \",clf.location)\n",
    "    print(\"experiment id : \",clf.id)\n",
    "    print(\"experiment status : \",clf.stage)\n",
    "    df_runs = clf.search_runs(exp_id)\n",
    "    df_runs.sort_values(\"metrics.accuracy_score\",ascending=True,inplace=True)\n",
    "\n",
    "    run_id = df_runs[\"run_id\"][0]\n",
    "    run_name = df_runs[\"run_name\"][0]\n",
    "\n",
    "    clf.register_model(\n",
    "        model_name=run_name,\n",
    "        run_id=run_id,\n",
    "    )\n",
    "    print(\"Best model run_id : \", run_id)\n",
    "    print(df_runs[['run_name', 'start_time', 'status']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f77cc-f24c-48d4-a9a8-a6b616119622",
   "metadata": {},
   "source": [
    "## Pipeline creation\n",
    "- In this method pipeline structure is created and volume is assigned to different components. `create_component_from_func` is used here to convert functions to components. add_pvolumes is used to attach private bucket to the component.\n",
    "\n",
    "    .after is used to create dependencies between components so that they execute sequencially without having any internal dependency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1bb1f60b-2e49-45a8-82f9-138adfce8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline()\n",
    "def katflow_kfp(\n",
    "        input_data: str\n",
    "    ):\n",
    "    \n",
    "    data_path = \"/kfs_public/data_dir\"\n",
    "    exp_name = 'diabetes_prediction3'\n",
    "    \n",
    "    split_data_op = create_component_from_func(split_data)\n",
    "    create_classifier_op = create_component_from_func(create_classifier)\n",
    "    decision_tree_op = create_component_from_func(decision_tree)\n",
    "    random_forest_op = create_component_from_func(random_forest)\n",
    "    show_runs_op = create_component_from_func(show_runs)\n",
    "    register_best_model_op = create_component_from_func(register_best_model)\n",
    "    \n",
    "    split_data_task = split_data_op(input_data, data_path).add_pvolumes({ '/kfs_private':dsl.PipelineVolume(pvc=\"private-storage-08a7de14\") })\n",
    "    create_classifier_task = create_classifier_op(exp_name).add_pvolumes({ '/kfs_private':dsl.PipelineVolume(pvc=\"private-storage-08a7de14\") })\n",
    "    create_classifier_task.after(split_data_task)\n",
    "    random_forest_task = random_forest_op(exp_name).add_pvolumes({ '/kfs_private':dsl.PipelineVolume(pvc=\"private-storage-08a7de14\") })\n",
    "    decision_tree_task = decision_tree_op(exp_name).add_pvolumes({ '/kfs_private':dsl.PipelineVolume(pvc=\"private-storage-08a7de14\") })\n",
    "    random_forest_task.after(create_classifier_task) # random_forest_task executes after create_classifier_task\n",
    "    decision_tree_task.after(create_classifier_task)\n",
    "    show_runs_task = show_runs_op(exp_name).add_pvolumes({ '/kfs_private':dsl.PipelineVolume(pvc=\"private-storage-08a7de14\") })\n",
    "    show_runs_task.after(random_forest_task, decision_tree_task) # show_runs_task runs after random_forest_task and  decision_tree_task\n",
    "    register_best_model_task = register_best_model_op(exp_name).add_pvolumes({ '/kfs_private':dsl.PipelineVolume(pvc=\"private-storage-08a7de14\") })\n",
    "    register_best_model_task.after(show_runs_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68fce5-738e-4621-9f3d-e3647d3e6826",
   "metadata": {},
   "source": [
    "## Compile and run pipeline\n",
    "- Here the pipeline is compiled and starts running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f6029a0b-a07f-468a-8ee6-8a69b47e8f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to read a token from file '/var/run/secrets/kubeflow/pipelines/token' ([Errno 2] No such file or directory: '/var/run/secrets/kubeflow/pipelines/token').\n",
      "WARNING:root:Failed to set up default credentials. Proceeding without credentials...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/5cad9b53-4472-43fb-8120-c868735eef0f\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=/pipeline/#/pipelines/details/10f97736-c79d-49ef-a1e1-6054797150f0>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/8c37def1-d5d4-4f66-8de1-5bc5a9f854e0\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "EXPERIMENT_NAME = \"katflow_kfp1\"\n",
    "pipeline_func = katflow_kfp\n",
    "arguments={\n",
    "    \"input_data\": \"/kfs_pulic/diabetes.csv\",\n",
    "    }\n",
    "pipeline_filename = pipeline_func.__name__ + f'{uuid.uuid1()}.pipeline.yaml'\n",
    "kfp.compiler.Compiler().compile(pipeline_func, pipeline_filename)\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "run_name = pipeline_func.__name__ + str(datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\"))\n",
    "client.upload_pipeline(pipeline_filename)\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3a620-cd46-413b-84f6-78d69b435559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
