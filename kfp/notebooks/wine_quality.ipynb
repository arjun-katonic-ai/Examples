{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb91813-f4c2-4edd-aadb-fdfeac259303",
   "metadata": {},
   "source": [
    "# This Notebook focuses on a wine quality usecase with different flavours of kfp sdk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373e7f56-9274-4acc-830f-765db2610a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import components\n",
    "from kfp import dsl\n",
    "from typing import List\n",
    "import kfp\n",
    "from typing import NamedTuple\n",
    "from kfp.components import func_to_container_op, create_component_from_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6285d9-f417-4762-9cfe-86fcfdc812c8",
   "metadata": {},
   "source": [
    "## Read and save data\n",
    "- This method loads the data from the load_wine from sklearn.datasets and saves it\n",
    "    to `/kfs_private/data_dir` as train.csv and test.csv and @create_component_from_func decorator is used to conver this function into a component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1eb1c2-7f96-4c9d-adea-fef42179ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def get_data():\n",
    "    import os\n",
    "    os.system(\"pip install pandas scikit-learn\")\n",
    "    import pandas as pd\n",
    "    from sklearn.datasets import load_wine\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x, y = load_wine(return_X_y=True)\n",
    "    x = pd.DataFrame(x)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    x_train['y'] = y_train\n",
    "    x_test['y'] = y_test\n",
    "\n",
    "    x_train.to_csv('/kfs_private/data_dir/train.csv', index=False)\n",
    "    x_test.to_csv('kfs_private/data_dir/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3164aa1-8835-407e-92e7-0a0b559c4079",
   "metadata": {},
   "source": [
    "## Decision tree\n",
    "- This method reads `train.csv` and `test.csv` from `/kfs_private/data_dir` and creating a DecisionTreeClassifier object and printing the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac78d68b-4d88-4b4f-a933-0e452621d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func # This is another way to create component from function, to use create_component_from_func as a decorator\n",
    "def decision_tree():\n",
    "    import os\n",
    "    os.system(\"pip install pandas scikit-learn\")\n",
    "    import pandas as pd\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    train = pd.read_csv('/kfs_private/data_dir/train.csv')\n",
    "    test = pd.read_csv('/kfs_private/data_dir/test.csv')\n",
    "    x_train, y_train = train.drop(columns=['y'], axis=1), train['y']\n",
    "    x_test, y_test = test.drop(columns=['y'], axis=1), test['y']\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e185a42e-094e-4dce-879a-f73dd41b090e",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "- This method reads `train.csv` and `test.csv` from `/kfs_private/data_dir` and creating a Logistic Regression object and printing the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "543141b0-0a16-4ce3-9df7-c50108727e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def logistic_regression():\n",
    "    import os\n",
    "    os.system(\"pip install pandas scikit-learn\")\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    train = pd.read_csv('/kfs_private/data_dir/train.csv')\n",
    "    test = pd.read_csv('/kfs_private/data_dir/test.csv')\n",
    "    x_train, y_train = train.drop(columns=['y'], axis=1), train['y']\n",
    "    x_test, y_test = test.drop(columns=['y'], axis=1), test['y']\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d004c75-6cee-45b1-950a-7002b0f564d6",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "- This method reads `train.csv` and `test.csv` from `/kfs_private/data_dir` and creating a RandomForestClassifier object and printing the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f1db24-6ade-475b-a741-450772e7b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def random_forest():\n",
    "    import os\n",
    "    os.system(\"pip install pandas scikit-learn\")\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    train = pd.read_csv('/kfs_private/data_dir/train.csv')\n",
    "    test = pd.read_csv('/kfs_private/data_dir/test.csv')\n",
    "    x_train, y_train = train.drop(columns=['y'], axis=1), train['y']\n",
    "    x_test, y_test = test.drop(columns=['y'], axis=1), test['y']\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728af50-5c15-4a76-a57b-db939e6424bb",
   "metadata": {},
   "source": [
    "## Exit handler\n",
    "- This method is going to be used as a exit handler for the pipeline\n",
    "\n",
    "    that means this method is going to be executed at the end of the pipeline regardless, wheather pipeline executes successfully or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91842975-8ac5-4a81-98b6-dd8854304a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def echo_msg(msg: str):\n",
    "    \"\"\"Echo a message by parameter.\"\"\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866751b3-99a4-44f0-9c56-af88ffdab5d2",
   "metadata": {},
   "source": [
    "## Pipeline creation\n",
    "- This method is where the pipeline design is happening. All of the components are kept under dsl.ExitHandler, so that they get executed first then at the end exit_task gets executed. This exit handler can be used to do something that is necessary even if the pipeline fails.\n",
    "\n",
    "- .after is used with a component to create dependencies between different components, so that they don't execute parallally but gets executed sequencially even without any internal dependency between component.\n",
    "\n",
    "- .set_retry() is used to re-run a compoent if it fails, because the failure can be due to some internal issue and can be resolved with a re-run. Then instead of reruning a entire pipeline using .set_retry() and passing number of times to retry can be save a lot of time and resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4718df41-4825-4b9f-b150-a4827d3c8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='Wine quality pipeline',\n",
    "    description='A pipeline that trains on wine quality dataset'\n",
    ")\n",
    "def wine_pipeline():\n",
    "\n",
    "    exit_task = echo_msg('Pipeline finished running.Exiting.....')\n",
    "    # dsl.ExitHandler, this helps in control what happends at the end of the pipeline\n",
    "    with dsl.ExitHandler(exit_task): \n",
    "        get_data_task = get_data().add_pvolumes({ '/kfs_private':dsl.PipelineVolume(pvc=\"private-storage-08a7de14\") }).set_retry(2) # if the pod fails it'll try to re-execute it\n",
    "        logistic_regression_task = logistic_regression().add_pvolumes({ '/kfs_private':dsl.PipelineVolume(pvc=\"private-storage-08a7de14\") }).set_retry(2)\n",
    "        random_forest_task = random_forest().add_pvolumes({ '/kfs_private':dsl.PipelineVolume(pvc=\"private-storage-08a7de14\") }).set_retry(2)\n",
    "        decision_tree_task = decision_tree().add_pvolumes({ '/kfs_private':dsl.PipelineVolume(pvc=\"private-storage-08a7de14\") }).set_retry(2)\n",
    "        random_forest_task.after(get_data_task) # random_forest_task executes after get_data_task\n",
    "        decision_tree_task.after(get_data_task)\n",
    "        logistic_regression_task.after(get_data_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da20b9c3-f595-4bd1-a133-46073d7fcb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to read a token from file '/var/run/secrets/kubeflow/pipelines/token' ([Errno 2] No such file or directory: '/var/run/secrets/kubeflow/pipelines/token').\n",
      "WARNING:root:Failed to set up default credentials. Proceeding without credentials...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/79500081-e281-461e-8a78-c026af2d8fee\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=/pipeline/#/pipelines/details/9b78058e-5364-4b33-a9b3-bb8b8f98ad7a>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/78c9f992-a1c7-4175-b0f7-2a4573692cad\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import uuid\n",
    "EXPERIMENT_NAME = \"wine_pipeline\"\n",
    "pipeline_func = wine_pipeline\n",
    "arguments={}\n",
    "pipeline_filename = pipeline_func.__name__ + f'{uuid.uuid1()}.pipeline.yaml'\n",
    "kfp.compiler.Compiler().compile(pipeline_func, pipeline_filename)\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "run_name = pipeline_func.__name__ + str(datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\"))\n",
    "client.upload_pipeline(pipeline_filename)\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee1ae7bb-73e5-44f4-90d9-fb4716bef759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "client.upload_pipeline_version(pipeline_filename, uuid.uuid1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c54592-7677-4f14-9f1d-3e18e636c4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
